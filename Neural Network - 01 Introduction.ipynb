{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "A neural network is a network of neurons that are connected to each other. Generally the neural network will have an input layer, an output layer and one or more hidden layers. Every neuron is connected to all neurons in the subsequent layer and each connection has a weight while each neuron has a bias. The weights and bias are randomly assigned at initialization.\n",
    "\n",
    "The network is then trained by tuning the weights and biases till we reach a point where a given input yields the expected output.\n",
    "\n",
    "## Unsupervised Learning\n",
    "If you want to extract patterns from a set of unlabelled data – then you use either a Restricted Boltzmann\n",
    "Machine, or an autoencoder.\n",
    "\n",
    "## Supervised Learning\n",
    "If you have labeled data and you want to build a classifier, you have several different options depending on your application.\n",
    "\n",
    "1. For text processing tasks like sentiment analysis, parsing, and named entity recognition – use a Recurrent Net or a Recursive Neural Tensor Network(RNTN).\n",
    "\n",
    "1. For any language model that operates on the character level, use a Recurrent Net.\n",
    "\n",
    "1. For image recognition, use a Deep Belief Network or a Convolutional Net.\n",
    "\n",
    "1. For object recognition, use a Convolutional Net or an RNTN.\n",
    "\n",
    "1. For speech recognition, use a Recurrent Net.\n",
    "\n",
    "In general, Deep Belief Networks and Multilayer Perceptrons with rectified linear units – also known as RELU – are both good choices for classification. For time series analysis, it’s best to use a Recurrent Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.5 (default, Jul 28 2020, 12:59:40) \n",
      "[GCC 9.3.0]\n",
      "Numpy: 1.18.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Numpy:\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network using python\n",
    "We can build a simple Neural netowrk without using any frameworks like Tensorflow or pytorch. Lets try to do that using python\n",
    "\n",
    "### Coding a layer\n",
    "\n",
    "Lets say that you have 3 inputs to a neuron (these are ouputs from a previous layer, in this case that layer had 3 neurons). Each input will have a value and each connection will have a weight. To calculate the output of this neuron, we simply sum up the product if input value and weights. Finally we add the bias. See the example below\n",
    "\n",
    "```\n",
    "1.1-----.2------|~~~~|\n",
    "2.1-----.9------| 4  |-----------> 5.27\n",
    "1.2-----.7------|____|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2700000000000005\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.1, 2.1, 1.2]\n",
    "weights = [0.2, 0.9, -0.7]\n",
    "bias = 4\n",
    "\n",
    "output = 0\n",
    "for ii in range(len(inputs)):\n",
    "    output += inputs[ii] * weights[ii]\n",
    "\n",
    "output += bias\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2700000000000005\n"
     ]
    }
   ],
   "source": [
    "# numpy makes it even simpler. Realize that what we did above is called a dot product in maths !!\n",
    "output = np.dot(inputs, weights) + bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is done at every neuron. When the network is being trained, this process is repeated several times by adjust the weights and biases of all the neurons in the network to find an optimal setting where every training input delivers the traiing output. Once the model is trianed, then we can input a test data and see the results.\n",
    "\n",
    "\n",
    "### Define Layer\n",
    "\n",
    "Now lets define a Neuron Class and a Layer CLass. We will use these to build a model next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class Neuron(object):\n",
    "    def __init__(self, num_inputs):\n",
    "        self.bias = random.randint(0,9)\n",
    "        #self.weights = [random.random() for _ in range(num_inputs)]\n",
    "        self.weights = np.random.randn(num_inputs)\n",
    "\n",
    "    # for printing\n",
    "    def __repr__(self):\n",
    "        return f\"Node bias is: {self.bias} and weight is: {self.weights}\"\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, neurons):\n",
    "        self.len = len(neurons)\n",
    "        self.neurons = neurons\n",
    "        self.outputs = None\n",
    "\n",
    "    def forward(self, layer_inputs):\n",
    "        self.outputs = [ np.dot(n.weights, layer_inputs) + n.bias for n in self.neurons ]\n",
    "        return self.outputs\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model\n",
    "Lets create a model with two layers. The first layer has 3 neurons and 5 inputs. The second layer has just 1 neuron.\n",
    "\n",
    "5 inputs --> layer 1(3 neurons)------>layer 2(1 neuron) ----> 1 output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node bias is: 1 and weight is: [1.6843625  1.02702216 1.88164117 1.17060424 0.19434945]\n",
      "Test Data: [-0.72505057 -0.51609522 -1.43590574 -0.71248967  0.72229096]\n",
      "Layer 1: [-4.146815159777426, 8.783391550848012, 8.753012652554899]\n",
      "layer 2: [4.885304825861041]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "NUM_NODES = 3\n",
    "NUM_INPUTS = 5\n",
    "\n",
    "# create 2 neurons each with 5 inputs\n",
    "nodes = [Neuron(NUM_INPUTS) for ii in range(NUM_NODES)]\n",
    "print(nodes[0])\n",
    "\n",
    "# create input layer using these nodes. This layer will have 2 outputs since it has 2 nodes.\n",
    "layer1 = Layer(nodes)\n",
    "\n",
    "# lets create an output layer with just one neuron. Inputs in this layer is output from prev layer\n",
    "nodes = [Neuron(layer1.len)]\n",
    "layer2 = Layer(nodes)\n",
    "\n",
    "# Test data\n",
    "#ts_data = [random.random() for _ in range(NUM_INPUTS)]\n",
    "ts_data = np.random.randn(NUM_INPUTS)\n",
    "\n",
    "# Now feed the input thru layers.\n",
    "print(\"Test Data:\", ts_data)\n",
    "print(\"Layer 1:\", layer1.forward(ts_data))\n",
    "print(\"layer 2:\", layer2.forward(layer1.outputs))\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "Every neuron in hidden layers (and output layers) will also have an activation function with it that further changes the ouput from that neuron. Activation functions are mathematical equations that determine whether a neuron should be activated (“fired”) or not. They also help normalize the output of each neuron to a range between 1 and 0 or between -1 and 1.\n",
    "\n",
    "1. Step Activation Function\n",
    "1. Sigmoid Activation Function\n",
    "1. (Rectified Linear Unit) Activation Function - Most commonly used.\n",
    "\n",
    "No lets add an activation function to the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.outputs = np.maximum(0, inputs)\n",
    "        return self.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data: [ 1.23409924 -0.78939283  1.21321803 -0.79087021  1.64496744]\n",
      "Layer 1: [5.088537886931036, -0.9620679361881948, 10.780068708298156]\n",
      "Layer 1 Activation: [ 5.08853789  0.         10.78006871]\n",
      "layer 2: [-5.593457901319399]\n",
      "Layer 2 Activation: [0.]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now feed the input thru layers applyling Activation funtion\n",
    "act = Activation_ReLU()\n",
    "print(\"Test Data:\", ts_data)\n",
    "print(\"Layer 1 :\", layer1.forward(ts_data))\n",
    "print(\"Layer 1 Activation:\", act.forward(layer1.outputs))\n",
    "print(\"layer 2:\", layer2.forward(act.outputs))\n",
    "print(\"Layer 2 Activation:\", act.forward(layer2.outputs))\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes a very basic indroduction to a neuran networks. There are frameworks available that make it easier to create and train models. One of such framework is Tensorflow that we look into next.\n",
    "\n",
    "# Introduction to Tensorflow\n",
    "\n",
    "The links to notebooks are in the youtube description\n",
    "https://youtu.be/tPYj3fFJGjk\n",
    "\n",
    "A good introduction is available in [google ML course](https://developers.google.com/machine-learning/crash-course/first-steps-with-tensorflow/toolkit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.daisplay import clear_output\n",
    "!pip3 install tensorflow\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from '/home/chaudha4/.local/lib/python3.8/site-packages/tensorflow/_api/v2/version/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # now import the tensorflow module\n",
    "print(tf.version)  # make sure the version is 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "A tensor is an object that can be represented as an array (i.e. a Vector in mathematics)\n",
    "\n",
    "Each tensor has a data type and a shape. \n",
    "\n",
    "**Data Types Include**: float32, int32, string and others.\n",
    "\n",
    "**Shape**: Represents the dimension of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float64, numpy=324.1>\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([324, 122], dtype=int32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[3.567, 2.13 ],\n",
      "       [3.14 , 1.12 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "num1 = tf.Variable(324.1, dtype=tf.dtypes.float64)\n",
    "print(num1)\n",
    "num1 = tf.Variable([324, 122])\n",
    "print(num1)\n",
    "flo1 = tf.Variable([[3.567,2.13],[3.14, 1.12]], dtype=tf.dtypes.float32)\n",
    "print(flo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=string, numpy=\n",
      "array([[b'1', b'2'],\n",
      "       [b'this is a string', b'and me']], dtype=object)> (2, 2)\n"
     ]
    }
   ],
   "source": [
    "str1 = tf.Variable([[\"1\", \"2\"],[\"this is a string\", \"and me\"]], tf.string)\n",
    "print(str1, str1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank/Degree of Tensors\n",
    "Another word for rank is degree, these terms simply mean the number of dimensions involved in the tensor. What we created above is a *tensor of rank 0*, also known as a scalar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResourceVariable' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-1bc66952c479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResourceVariable' object has no attribute 'rank'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(str1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of Tensors\n",
    "Now that we've talked about the rank of tensors it's time to talk about the shape. The shape of a tensor is simply the number of elements that exist in each dimension. TensorFlow will try to determine the shape of a tensor but sometimes it may be unknown.\n",
    "\n",
    "To **get the shape** of a tensor we use the shape attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Shape\n",
    "The number of elements of a tensor is the product of the sizes of all its shapes. There are often many shapes that have the same number of elements, making it convient to be able to change the shape of a tensor.\n",
    "\n",
    "The example below shows how to change the shape of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]], shape=(2, 4, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[65 34 21 32 13]\n",
      "  [80 17 97 22 74]\n",
      "  [93 26 59 61 60]\n",
      "  [52 53 49 20 83]]\n",
      "\n",
      " [[74 85 46 42 54]\n",
      "  [35 63 60 11 65]\n",
      "  [91 97 34 35 19]\n",
      "  [ 6 81 70 40 11]]], shape=(2, 4, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.ones([2,4,5])\n",
    "print(t1)\n",
    "t1 = tf.random.uniform([2,4,5], minval=0,maxval=99, dtype=tf.dtypes.int32)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[26 95 64 31 10]\n",
      "  [79 29 16 57 23]]\n",
      "\n",
      " [[75 57  0 15 60]\n",
      "  [32 49 55 56 43]]\n",
      "\n",
      " [[33 49 79 33 93]\n",
      "  [ 0  1 44 46 25]]\n",
      "\n",
      " [[69 40 58 91 13]\n",
      "  [20 19 88  0 91]]], shape=(4, 2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t2 = tf.reshape(t1, [4, 2, -1])\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing Tensors\n",
    "You may be familiar with the term \"slice\" in python and its use on lists, tuples etc. Well the slice operator can be used on tensors to select specific axes or elements.\n",
    "\n",
    "When we slice or select elements from a tensor, we can use comma seperated values inside the set of square brackets. Each subsequent value refrences a different dimension of the tensor.\n",
    "\n",
    "Ex: ```tensor[dim1, dim2, dim3]```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[26 95 64 31 10]\n",
      " [79 29 16 57 23]\n",
      " [75 57  0 15 60]\n",
      " [32 49 55 56 43]], shape=(4, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# first row\n",
    "print(t1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([79 29 16 57 23], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# first 2nd element from 1st row\n",
    "print(t1[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[75 57  0 15 60]\n",
      " [69 40 58 91 13]], shape=(2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 2nd element from all rows\n",
    "print(t1[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([15 91], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(t1[:, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Tensors\n",
    "Before we go to far, I will mention that there are diffent types of tensors. These are the most used and we will talk more in depth about each as they are used.\n",
    "- Variable\n",
    "- Constant\n",
    "- Placeholder\n",
    "- SparseTensor\n",
    "\n",
    "With the execption of ```Variable``` all these tensors are immuttable, meaning their value may not change during execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[10 20]\n",
      " [30 40]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "print(a)\n",
    "\n",
    "# Broadcasting support\n",
    "b = tf.add(a, 1)\n",
    "print(b)\n",
    "\n",
    "print(tf.multiply(a, 10))\n",
    "\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [12 20]]\n"
     ]
    }
   ],
   "source": [
    "# Use NumPy values\n",
    "import numpy as np\n",
    "\n",
    "c = np.multiply(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# Obtain numpy value from a tensor:\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression vs. classification\n",
    "\n",
    "A regression model predicts continuous values. For example, regression models make predictions that answer questions like the following:\n",
    "\n",
    "    What is the value of a house in California?\n",
    "\n",
    "    What is the probability that a user will click on this ad?\n",
    "\n",
    "A classification model predicts discrete values. For example, classification models make predictions that answer questions like the following:\n",
    "\n",
    "    Is a given email message spam or not spam?\n",
    "\n",
    "    Is this an image of a dog, a cat, or a hamster?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
